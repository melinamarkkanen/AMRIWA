SAMPLES, = glob_wildcards("data/{sample}_R1_001.fastq.gz")

rule all:
	input:
		expand("data/FASTQC/{sample}_{read}_001_fastqc.zip", sample=SAMPLES, read=["R1", "R2"]),
		expand("trimmed_data/FASTQC/{sample}_{read}_trimmed_fastqc.zip", sample=SAMPLES, read=["R1", "R2"]),
		"data/multiqc_report.html",
		"trimmed_data/multiqc_report.html",
		expand("metaphlan3/{sample}_profile.txt", sample=SAMPLES),
		"metaphlan3/merged_abundance_table.txt",
		"resfinder_db/resfinder.1.bt2",
		expand("trimmed_data/{sample}_{read}_trimmed.fastq.gz", sample=SAMPLES, read=["R1", "R2"]),
		expand("mapped_reads/{sample}_unfiltered.bam", sample=SAMPLES),
		expand("logs/bowtie2/{sample}.log", sample=SAMPLES),
		expand("sorted_reads/{sample}.bam", sample=SAMPLES),
		expand("sorted_reads/{sample}.bam.bai", sample=SAMPLES),
		"resfinder_out/ARG_genemat.txt",
		"CARD/protein_fasta_protein_homolog_model.dmnd",
		expand("CARD/{sample}_{read}_CARD.txt", sample=SAMPLES, read=["R1", "R2"]),
		"MGE_db/MGE.1.bt2",
                expand("mapped_reads_MGE/{sample}_unfiltered.bam", sample=SAMPLES),
                expand("logs/MGE/{sample}.log", sample=SAMPLES),
                expand("mapped_reads_MGE/{sample}.bam", sample=SAMPLES),
                expand("sorted_reads_MGE/{sample}.bam.bai", sample=SAMPLES),
                "MGE_out/MGE_genemat.txt",
		"VFDB_db/VFDB_setB_pro.dmnd",
		"VFDB_db/VFDB_out.txt",
                "rpoB/RNA_pol_Rpb2_1",
                expand("fasta/AA_renamed_{sample}_{read}.fasta.gz", sample=SAMPLES, read=["R1", "R2"]),
                expand("rpoB/{sample}_{read}_hmm_out.txt", sample=SAMPLES, read=["R1", "R2"]),
                expand("rpoB/{sample}_{read}_HMM_count.txt", sample=SAMPLES, read=["R1", "R2"])

rule fastqc_raw:
	input:
		"data/{sample}_{read}_001.fastq.gz"
	output:
		"data/FASTQC/{sample}_{read}_001_fastqc.zip"
	message:
		"-- Quality check of raw data with Fastqc --"
	conda:
		"envs/QC_env.yml"
	threads:
		2
	shell:
              "fastqc --quiet -t {threads} --outdir data/FASTQC -f fastq {input}"

rule multiqc_raw:
	input:
		expand("data/FASTQC/{sample}_{read}_001_fastqc.zip", sample=SAMPLES, read=["R1", "R2"])
	output:
		"data/multiqc_report.html"
	message:
		"-- Running MultiQC for raw data --"
	conda:
		"envs/QC_env.yml"
	threads:
		1
	shell:
		"multiqc -f --interactive --quiet data/ -o data/"

rule cutadapt:
	input:
		fw= "data/{sample}_R1_001.fastq.gz",
		rv= "data/{sample}_R2_001.fastq.gz"
	output:
		fw= "trimmed_data/{sample}_R1_trimmed.fastq.gz",
		rv= "trimmed_data/{sample}_R2_trimmed.fastq.gz",
		log= "trimmed_data/{sample}.trimmed.txt"
	message:
		"-- Running Cutadapt --"
	conda:
		"envs/cutadapt.yml"
	threads:
		1
	shell:
		"cutadapt -a CTGTCTCTTATACACATCT -A CTGTCTCTTATACACATCT -O 10 -m 30 -q 20 \
                                {input.fw} {input.rv} -o {output.fw} -p {output.rv} > {output.log}"

rule fastqc_trim:
	input:
		"trimmed_data/{sample}_{read}_trimmed.fastq.gz"
	output:
		"trimmed_data/FASTQC/{sample}_{read}_trimmed_fastqc.zip"
	message:
		"-- Quality check of trimmed data with Fastqc --"
	conda:
		"envs/QC_env.yml"
	threads:
		2
	shell:
		"fastqc --quiet -t {threads} --outdir trimmed_data/FASTQC -f fastq {input}"

rule multiqc_trim:
	input:
		expand("trimmed_data/FASTQC/{sample}_{read}_trimmed_fastqc.zip", sample=SAMPLES, read=["R1", "R2"])
	output:
		"trimmed_data/multiqc_report.html"
	message:
		"-- Running MultiQC for trimmed data--"
	conda:
		"envs/QC_env.yml"
	shell:
		"multiqc -f --interactive --quiet trimmed_data/ -o trimmed_data/"

rule metaphlan3:
        input:
		reads= "trimmed_data/{sample}_R1_trimmed.fastq.gz"
        output:
		file= "metaphlan3/{sample}_profile.txt",
		bowtie2out= "metaphlan3/{sample}.bowtie2.bz2"
        message:
                "-- Running Metaphlan3 --"
        conda:
                "envs/humann3.yml"
        threads:
                2
        shell:
#		metaphlan --install
		"metaphlan {input.reads} --nproc {threads} --bowtie2out {output.bowtie2out} --sample_id {wildcards.sample} --input_type fastq > {output.file}"

rule metaphlan3_merge:
	input:
		expand("metaphlan3/{sample}_profile.txt", sample=SAMPLES)
	output:
		"metaphlan3/merged_abundance_table.txt"
	message:
		"-- Merging Metaphlan3 results into table --"
	conda:
		"envs/humann3.yml"
	threads:
		1
	shell:
		"merge_metaphlan_tables.py {input} > {output}"

# Before rule "resfinder_db" create and remove duplicates from resfinder.fasta
#cat *.fsa > resfinder.fasta
#seqkit rmdup -s resfinder.fasta > unique_resfinder.fasta -d removed
#[INFO] 18 duplicated records removed
#mv unique_resfinder.fasta resfinder.fasta

rule resfinder_db:
	input:
		fasta= "resfinder_db/resfinder.fasta"
	output:
		indexed_db= "resfinder_db/resfinder.1.bt2"
	message:
		"-- ResFinder db --"
	conda:
		"envs/bowtie2.yml"
	threads:
		1
	shell:
		"bowtie2-build {input.fasta} resfinder_db/resfinder"

rule resfinder_mapping:
	input:
		fw= "trimmed_data/{sample}_R1_trimmed.fastq.gz",
		rv= "trimmed_data/{sample}_R2_trimmed.fastq.gz",
		indexed_db= "resfinder_db/resfinder.1.bt2"
	output:
		"mapped_reads/{sample}_unfiltered.bam"
	log:
		"logs/bowtie2/{sample}.log"
	message:
		"-- Mapping w/ ResFinder and extracting the mapped reads --"
	conda:
		"envs/bowtie2.yml"
	threads:
		1
	shell:
		"""
                (bowtie2 -x resfinder_db/resfinder -1 {input.fw} -2 {input.rv} -p {threads} -D 20 -R 3 -N 1 -L 20 -i S,1,0.50 | \
                samtools view -Sb - > {output}) 2> {log}
                """

rule resfinder_filtering:
	input:
		"mapped_reads/{sample}_unfiltered.bam"
	output:
		temp("mapped_reads/{sample}.bam")
	message:
		"-- Filtering reads for sorting --"
	conda:
		"envs/bowtie2.yml"
	threads:
		1
	shell:
		"""
                samtools view -h {input} | awk 'BEGIN {{FS="\t"; OFS="\t"}} \
                {{if (/^@/ && substr($2, 3, 1)==":") {{print}} \
                else if (($7!="=" || $7=="=") && and($2, 0x40)) {{print}}}}' \
                | samtools view -Shu - > {output}
                """
# The resulting reads correspond to the following samtools flags:
#samtools view BFH19_S137.bam | awk '{print $2}' | sort | uniq
# 101*, 113, 65, 69*, 73, 77*, 81, 83, 89, 97, 99 
##(* will be excluded in the next step, since these are unmapped reads) 

rule resfinder_sorting:
	input:
		"mapped_reads/{sample}.bam"
	output:
		"sorted_reads/{sample}.bam"
	message:
		"-- Sorting reads --"
	conda:
		"envs/bowtie2.yml"
	threads:
		1
	shell:
		"samtools sort -T sorted_reads/{wildcards.sample} "
		"-O bam {input} > {output}"

rule resfinder_indexing:
	input:
		"sorted_reads/{sample}.bam"
	output:
		"sorted_reads/{sample}.bam.bai"
	message:
		"-- Indexing mapped reads --" 	
	conda:
		"envs/bowtie2.yml"      
	threads:
		1
	shell:
		"samtools index {input}"

rule combine_results_1:
	input:
		"sorted_reads/BFH1_S123.bam"
	output:
		temp("resfinder_out/gene_names")
	message:
		"-- Creating gene_names file --"
	conda:
		"envs/bowtie2.yml"
	threads:
		1
	shell:
		"""
		samtools idxstats {input} | grep -v "\*" | cut -f1 > {output}
		sed -i '1 i\GENE' {output}
		"""

rule combine_results_2:
	input:
		"sorted_reads/{sample}.bam"
	output:
		"resfinder_out/{sample}_counts"
	message:
		"-- Combine count data into genemat --"
	conda:
		"envs/bowtie2.yml"
	threads:
		1
	shell:
		"samtools idxstats {input} | grep -v "\*" | cut -f3 > {output}"

rule combine_results_3:
        input:
                "resfinder_out/{sample}_counts"
        output:
                temp("resfinder_out/renamed_{sample}_counts")
        message:
                "-- Adding sample names --"
        threads:
                1
        shell:
                "sed '1 i\{wildcards.sample}' {input} > {output}"

rule combine_results_4:
        input:
                gene_names= "resfinder_out/gene_names",
                counts= expand("resfinder_out/renamed_{sample}_counts", sample=SAMPLES)
        output:
                "resfinder_out/ARG_genemat.txt" 
        message:
                "-- Creating ARG_genemat --"
        threads:
                1
        shell:
                "paste {input.gene_names} {input.counts} > {output}"

rule fastq_to_fasta:
	input:
		"trimmed_data/{sample}_{read}_trimmed.fastq.gz"
	output:
		temp("fasta/{sample}_{read}.fasta.gz")
	message:
		"-- Converting fastq to FASTA --"
	conda:
		"envs/seqkit.yml"
	threads:
		1
	shell:
		"seqkit fq2fa {input} -o {output}"

rule rename_headers:
	input:
		R1="fasta/{sample}_R1.fasta.gz",
		R2="fasta/{sample}_R2.fasta.gz"
	output:
		R1="fasta/renamed_{sample}_R1.fasta.gz",
		R2="fasta/renamed_{sample}_R2.fasta.gz"
	message:
		"-- Adding sample names to multifasta file headers --"
	threads:
		1
	shell:
		"""
		zcat {input.R1} | sed 's/\(>\)/>{wildcards.sample}-/' | gzip > {output.R1}
		zcat {input.R2} | sed 's/\(>\)/>{wildcards.sample}-/' | gzip > {output.R2}
		"""

rule diamond_db:
	input:
		"CARD/protein_fasta_protein_homolog_model.fasta"
	output:
		"CARD/protein_fasta_protein_homolog_model.dmnd"
	message:
		"-- Creating DIAMOND database --"
	conda:
		"envs/diamond.yml"
	threads:
		1
	shell:
		"diamond makedb --in {input} -d CARD/protein_fasta_protein_homolog_model"

rule run_diamond:
	input:
		fasta= "fasta/renamed_{sample}_{read}.fasta.gz",
		db= "CARD/protein_fasta_protein_homolog_model.dmnd"
	output:
		"CARD/{sample}_{read}_CARD.txt"
	message:
		"-- Running DIAMOND --"
	conda:
		"envs/diamond.yml"
	threads:
		10
	shell:
		"""
                gunzip -c {input.fasta} | \
                diamond blastx -d CARD/protein_fasta_protein_homolog_model -q - --max-target-seqs 1 --out {output} --threads {threads} --outfmt 6 --evalue 1e-5
                """
rule MGE_db:
        input:
                fasta= "MGE_db/MGE.fasta"
        output:
                indexed_db= "MGE_db/MGE.1.bt2"
        message:
                "-- MGE db --"
        conda:
                "envs/bowtie2.yml"
        threads:
                1
        shell:
                "bowtie2-build {input.fasta} MGE_db/MGE"

rule MGE_mapping:
        input:
                fw= "trimmed_data/{sample}_R1_trimmed.fastq.gz",
                rv= "trimmed_data/{sample}_R2_trimmed.fastq.gz",
                indexed_db= "MGE_db/MGE.1.bt2"
        output:
                temp("mapped_reads_MGE/{sample}_unfiltered.bam")
        log:
                "logs/MGE/{sample}.log"
        message:
                "-- Mapping w/ MGEs --"
        conda:
                "envs/bowtie2.yml"
        threads:
                6
        shell:
                """
                (bowtie2 -x MGE_db/MGE -1 {input.fw} -2 {input.rv} -p {threads} -D 20 -R 3 -N 1 -L 20 -i S,1,0.50 | \
                samtools view -Sb - > {output}) 2> {log}
                """

rule MGE_filtering:
        input:
                "mapped_reads_MGE/{sample}_unfiltered.bam"
        output:
                temp("mapped_reads_MGE/{sample}.bam")
        message:
                "-- Filtering reads for sorting --"
        conda:
                "envs/bowtie2.yml"
        threads:
                6
        shell:
                """
                samtools view -h {input} | awk 'BEGIN {{FS="\t"; OFS="\t"}} \
                {{if (/^@/ && substr($2, 3, 1)==":") {{print}} \
                else if (($7!="=" || $7=="=") && and($2, 0x40)) {{print}}}}' \
                | samtools view -Shu - > {output}
                """

rule MGE_sorting:
        input:
                "mapped_reads_MGE/{sample}.bam"
        output:
                "sorted_reads_MGE/{sample}.bam"
        message:
                "-- Sorting reads --"
        conda:
                "envs/bowtie2.yml"
        threads:
                6
        shell:
                "samtools sort -T sorted_reads_MGE/{wildcards.sample} "
                "-O bam {input} > {output}"

rule MGE_indexing:
        input:
                "sorted_reads_MGE/{sample}.bam"
        output:
                "sorted_reads_MGE/{sample}.bam.bai"
        message:
                "-- Indexing mapped reads --"   
        conda:
                "envs/bowtie2.yml"      
        threads:
                6
        shell:
                "samtools index {input}"

rule combine_MGE_results_1:
        input:
                "sorted_reads_MGE/BFH1_S123.bam"
        output:
                temp("MGE_out/gene_names")
        message:
                "-- Creating gene_names file --"
        conda:
                "envs/bowtie2.yml"
        threads:
                1
        shell:
                """
                samtools idxstats {input} | grep -v "\*" | cut -f1 > {output}
                sed -i '1 i\GENE' {output}
                """

rule combine_MGE_results_2:
        input:
                "sorted_reads_MGE/{sample}.bam"
        output:
                "MGE_out/{sample}_counts"
        message:
                "-- Combine count data into genemat --"
        conda:
                "envs/bowtie2.yml"
        threads:
                1
        shell:
                """
                samtools idxstats {input} | grep -v "\*" | cut -f3 > {output}
                """

rule combine_MGE_results_3:
        input:
                "MGE_out/{sample}_counts"
        output:
                temp("MGE_out/renamed_{sample}_counts")
        message:
                "-- Adding sample names --"
        threads:
                1
        shell:
                "sed '1 i\{wildcards.sample}' {input} > {output}"

rule combine_MGE_results_4:
        input:
                gene_names= "MGE_out/gene_names",
                counts= expand("MGE_out/renamed_{sample}_counts", sample=SAMPLES)
        output:
                "MGE_out/MGE_genemat.txt" 
        message:
                "-- Creating MGE_genemat --"
        threads:
                1
        shell:
                "paste {input.gene_names} {input.counts} > {output}"

rule diamond_db_VFDB:
        input:
                "VFDB_db/VFDB_setB_pro.fas"
        output:
                "VFDB_db/VFDB_setB_pro.dmnd"
        message:
                "-- Creating DIAMOND database for VFDB --"
        conda:
                "envs/diamond.yml"
        threads:
                6
        shell:
                "diamond makedb --in {input} -d VFDB_db/VFDB_setB_pro"

rule run_diamond_VFDB:
        input:
                fasta= expand("fasta/renamed_{sample}_{read}.fasta.gz", sample=SAMPLES, read=["R1", "R2"]),
                db= "VFDB_db/VFDB_setB_pro.dmnd"
        output:
                "VFDB_db/VFDB_out.txt"
        message:
                "-- Running DIAMOND for VFDB --"
        conda:
                "envs/diamond.yml"
        threads:
                10
        shell:
                """
                gunzip -c {input.fasta} | \
                diamond blastx -d VFDB_db/VFDB_setB_pro -q - --max-target-seqs 1 --out {output} --threads {threads} --outfmt 6 --evalue 1e-5
                """

rule HMM_profile_1:
        input:
                "rpoB/Pfam-A.hmm.gz"
        output:
                "rpoB/Pfam-A.hmm"
        message:
                "-- Fetch profile for rpoB from Pfam-A --"
        conda:
                "envs/hmmer.yml"
        threads:
                1
        shell:
                "gunzip {input}"

rule HMM_profile_2:
        input:
              "rpoB/Pfam-A.hmm"
        output:
               prof= "rpoB/RNA_pol_Rpb2_1"
        message:
               "-- Fetch profile for rpoB from Pfam-A --"
        conda:
              "envs/hmmer.yml"
        threads:
               1
        shell:
                """
                hmmpress {input}
                hmmfetch {input} PF04563.16 > {output.prof}
                """

rule translate_into_AA:
        input:
                fasta= "fasta/renamed_{sample}_{read}.fasta.gz"
        output:
                temp("fasta/tempAA_renamed_{sample}_{read}.fasta.gz")
        message:
                "-- Translating fasta reads into AA sequences --"
        conda:
                "envs/seqkit.yml"
        threads:
                10
        shell:
                """
                gunzip -c {input.fasta} | \
                seqkit translate - --frame 6 --trim | gzip > {output}
                """

rule modify_AA_files:
        input:
                "fasta/tempAA_renamed_{sample}_{read}.fasta.gz"
        output:
                temp("fasta/AA_renamed_{sample}_{read}.fasta.gz")
        message:
                "-- Modify AA sequences --"
        threads:
                1
        shell:
                """
                zcat {input} | sed '1d' | \
                gzip > {output}
                """

rule run_hmmsearch:
        input:
                prof= "rpoB/RNA_pol_Rpb2_1",
                fasta= "fasta/AA_renamed_{sample}_{read}.fasta.gz"
        output:
                "rpoB/{sample}_{read}_hmm_out.txt"
        message:
                "-- Running hmmsearch --"
        conda:
                "envs/hmmer.yml"
        threads:
                10
        shell:
                "hmmsearch --tblout {output} --cpu {threads} {input.prof} {input.fasta}"

rule count_hmm_results:
        input:
                "rpoB/{sample}_{read}_hmm_out.txt"
        output:
                "rpoB/{sample}_{read}_HMM_count.txt"
        message:
                "-- Get counts from HMM results  --"
        threads:
                1
        shell:
                "grep -v -c '^#' {input} > {output}"

# ls *_hmm_out.txt | sed 's/_hmm_out.txt//g' > HMM_names.txt
# cat *_HMM_count.txt > HMM_counts.txt

#echo -e "sample_name" > HMM_sample_names.txt
#awk '0 == (NR + 1) % 2'  HMM_names.txt | sed 's/_R1//g' >> HMM_sample_names.txt

# read1
#echo -e "R1" > R1_HMM_counts
#awk '0 == (NR + 1) % 2'  HMM_counts.txt >> R1_HMM_counts

# read2
#echo -e "R2" > R2_HMM_counts
#awk '0 == NR % 2'  HMM_counts.txt >> R2_HMM_counts

#paste -d"\t" HMM_sample_names.txt R1_HMM_counts R2_HMM_counts > HMM_RESULT_TABLE.txt
